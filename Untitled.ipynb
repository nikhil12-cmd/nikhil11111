{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Definitions that don't fit elsewhere.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "__all__ = (\n",
    "    'DIGITS',\n",
    "    'LETTERS',\n",
    "    'CHARS',\n",
    "    'sigmoid',\n",
    "    'softmax',\n",
    ")\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "DIGITS = \"0123456789\"\n",
    "LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "CHARS = LETTERS + DIGITS\n",
    "\n",
    "def softmax(a):\n",
    "    exps = numpy.exp(a.astype(numpy.float64))\n",
    "    return exps / numpy.sum(exps, axis=-1)[:, numpy.newaxis]\n",
    "\n",
    "def sigmoid(a):\n",
    "  return 1. / (1. + numpy.exp(-a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-2rx9f0ng/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-61a42d11b642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mim_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-2rx9f0ng/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import collections\n",
    "import itertools\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "import common\n",
    "import model\n",
    "\n",
    "\n",
    "def make_scaled_ims(im, min_shape):\n",
    "    ratio = 1. / 2 ** 0.5\n",
    "    shape = (im.shape[0] / ratio, im.shape[1] / ratio)\n",
    "\n",
    "    while True:\n",
    "        shape = (int(shape[0] * ratio), int(shape[1] * ratio))\n",
    "        if shape[0] < min_shape[0] or shape[1] < min_shape[1]:\n",
    "            break\n",
    "        yield cv2.resize(im, (shape[1], shape[0]))\n",
    "\n",
    "\n",
    "def detect(im, param_vals):\n",
    "    \"\"\"\n",
    "    Detect number plates in an image.\n",
    "\n",
    "    :param im:\n",
    "        Image to detect number plates in.\n",
    "\n",
    "    :param param_vals:\n",
    "        Model parameters to use. These are the parameters output by the `train`\n",
    "        module.\n",
    "\n",
    "    :returns:\n",
    "        Iterable of `bbox_tl, bbox_br, letter_probs`, defining the bounding box\n",
    "        top-left and bottom-right corners respectively, and a 7,36 matrix\n",
    "        giving the probability distributions of each letter.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the image to various scales.\n",
    "    scaled_ims = list(make_scaled_ims(im, model.WINDOW_SHAPE))\n",
    "\n",
    "    # Load the model which detects number plates over a sliding window.\n",
    "    x, y, params = model.get_detect_model()\n",
    "\n",
    "    # Execute the model at each scale.\n",
    "    with tf.Session(config=tf.ConfigProto()) as sess:\n",
    "        y_vals = []\n",
    "        for scaled_im in scaled_ims:\n",
    "            feed_dict = {x: numpy.stack([scaled_im])}\n",
    "            feed_dict.update(dict(zip(params, param_vals)))\n",
    "            y_vals.append(sess.run(y, feed_dict=feed_dict))\n",
    "\n",
    "    # Interpret the results in terms of bounding boxes in the input image.\n",
    "    # Do this by identifying windows (at all scales) where the model predicts a\n",
    "    # number plate has a greater than 50% probability of appearing.\n",
    "    #\n",
    "    # To obtain pixel coordinates, the window coordinates are scaled according\n",
    "    # to the stride size, and pixel coordinates.\n",
    "    for i, (scaled_im, y_val) in enumerate(zip(scaled_ims, y_vals)):\n",
    "        for window_coords in numpy.argwhere(y_val[0, :, :, 0] >\n",
    "                                                       -math.log(1./0.99 - 1)):\n",
    "            letter_probs = (y_val[0,\n",
    "                                  window_coords[0],\n",
    "                                  window_coords[1], 1:].reshape(\n",
    "                                    7, len(common.CHARS)))\n",
    "            letter_probs = common.softmax(letter_probs)\n",
    "\n",
    "            img_scale = float(im.shape[0]) / scaled_im.shape[0]\n",
    "\n",
    "            bbox_tl = window_coords * (8, 4) * img_scale\n",
    "            bbox_size = numpy.array(model.WINDOW_SHAPE) * img_scale\n",
    "\n",
    "            present_prob = common.sigmoid(\n",
    "                               y_val[0, window_coords[0], window_coords[1], 0])\n",
    "\n",
    "            yield bbox_tl, bbox_tl + bbox_size, present_prob, letter_probs\n",
    "\n",
    "\n",
    "def _overlaps(match1, match2):\n",
    "    bbox_tl1, bbox_br1, _, _ = match1\n",
    "    bbox_tl2, bbox_br2, _, _ = match2\n",
    "    return (bbox_br1[0] > bbox_tl2[0] and\n",
    "            bbox_br2[0] > bbox_tl1[0] and\n",
    "            bbox_br1[1] > bbox_tl2[1] and\n",
    "            bbox_br2[1] > bbox_tl1[1])\n",
    "\n",
    "\n",
    "def _group_overlapping_rectangles(matches):\n",
    "    matches = list(matches)\n",
    "    num_groups = 0\n",
    "    match_to_group = {}\n",
    "    for idx1 in range(len(matches)):\n",
    "        for idx2 in range(idx1):\n",
    "            if _overlaps(matches[idx1], matches[idx2]):\n",
    "                match_to_group[idx1] = match_to_group[idx2]\n",
    "                break\n",
    "        else:\n",
    "            match_to_group[idx1] = num_groups \n",
    "            num_groups += 1\n",
    "\n",
    "    groups = collections.defaultdict(list)\n",
    "    for idx, group in match_to_group.items():\n",
    "        groups[group].append(matches[idx])\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "def post_process(matches):\n",
    "    \"\"\"\n",
    "    Take an iterable of matches as returned by `detect` and merge duplicates.\n",
    "\n",
    "    Merging consists of two steps:\n",
    "      - Finding sets of overlapping rectangles.\n",
    "      - Finding the intersection of those sets, along with the code\n",
    "        corresponding with the rectangle with the highest presence parameter.\n",
    "\n",
    "    \"\"\"\n",
    "    groups = _group_overlapping_rectangles(matches)\n",
    "\n",
    "    for group_matches in groups.values():\n",
    "        mins = numpy.stack(numpy.array(m[0]) for m in group_matches)\n",
    "        maxs = numpy.stack(numpy.array(m[1]) for m in group_matches)\n",
    "        present_probs = numpy.array([m[2] for m in group_matches])\n",
    "        letter_probs = numpy.stack(m[3] for m in group_matches)\n",
    "\n",
    "        yield (numpy.max(mins, axis=0).flatten(),\n",
    "               numpy.min(maxs, axis=0).flatten(),\n",
    "               numpy.max(present_probs),\n",
    "               letter_probs[numpy.argmax(present_probs)])\n",
    "\n",
    "\n",
    "def letter_probs_to_code(letter_probs):\n",
    "    return \"\".join(common.CHARS[i] for i in numpy.argmax(letter_probs, axis=1))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    im = cv2.imread(sys.argv[1])\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) / 255.\n",
    "\n",
    "    f = numpy.load(sys.argv[2])\n",
    "    param_vals = [f[n] for n in sorted(f.files, key=lambda s: int(s[4:]))]\n",
    "\n",
    "    for pt1, pt2, present_prob, letter_probs in post_process(\n",
    "                                                  detect(im_gray, param_vals)):\n",
    "        pt1 = tuple(reversed(map(int, pt1)))\n",
    "        pt2 = tuple(reversed(map(int, pt2)))\n",
    "\n",
    "        code = letter_probs_to_code(letter_probs)\n",
    "\n",
    "        color = (0.0, 255.0, 0.0)\n",
    "        cv2.rectangle(im, pt1, pt2, color)\n",
    "\n",
    "        cv2.putText(im,\n",
    "                    code,\n",
    "                    pt1,\n",
    "                    cv2.FONT_HERSHEY_PLAIN, \n",
    "                    1.5,\n",
    "                    (0, 0, 0),\n",
    "                    thickness=5)\n",
    "\n",
    "        cv2.putText(im,\n",
    "                    code,\n",
    "                    pt1,\n",
    "                    cv2.FONT_HERSHEY_PLAIN, \n",
    "                    1.5,\n",
    "                    (255, 255, 255),\n",
    "                    thickness=2)\n",
    "\n",
    "    cv2.imwrite(sys.argv[3], im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
